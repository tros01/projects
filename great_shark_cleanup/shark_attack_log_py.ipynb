{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a54c4cf0-9793-43a1-9f05-c1e3265d7728",
   "metadata": {},
   "source": [
    "# Shark attack log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "ab869a18-ad82-4922-aa09-baf0c27f84e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from skimpy import clean_columns\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "b91fd646-839a-4204-b9c9-a509db082a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "file_url = r\"https://www.sharkattackfile.net/spreadsheets/GSAF5.xls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "eb2d8e5f-7b7c-47a9-ab57-eb216d4c75e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(file_url, engine=\"xlrd\")\n",
    "# df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "80b35891-103a-4a10-a150-5c37e3b95a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7058 entries, 0 to 7057\n",
      "Data columns (total 23 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Date            7058 non-null   object \n",
      " 1   Year            7056 non-null   float64\n",
      " 2   Type            7040 non-null   object \n",
      " 3   Country         7008 non-null   object \n",
      " 4   State           6571 non-null   object \n",
      " 5   Location        6491 non-null   object \n",
      " 6   Activity        6473 non-null   object \n",
      " 7   Name            6839 non-null   object \n",
      " 8   Sex             6479 non-null   object \n",
      " 9   Age             4064 non-null   object \n",
      " 10  Injury          7023 non-null   object \n",
      " 11  Fatal Y/N       6497 non-null   object \n",
      " 12  Time            3532 non-null   object \n",
      " 13  Species         3927 non-null   object \n",
      " 14  Source          7038 non-null   object \n",
      " 15  pdf             6799 non-null   object \n",
      " 16  href formula    6794 non-null   object \n",
      " 17  href            6796 non-null   object \n",
      " 18  Case Number     6798 non-null   object \n",
      " 19  Case Number.1   6797 non-null   object \n",
      " 20  original order  6799 non-null   float64\n",
      " 21  Unnamed: 21     1 non-null      object \n",
      " 22  Unnamed: 22     2 non-null      object \n",
      "dtypes: float64(2), object(21)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# df structure\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b700d2d0-2d02-4897-84b1-a4d68d9b0d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7058, 23)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df dimensions\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70b0d1e-c946-4e3a-87d0-8f1fa55d4f21",
   "metadata": {},
   "source": [
    "## Data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "777bd59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean col names\n",
    "df = clean_columns(df)\n",
    "\n",
    "# Year as integer\n",
    "df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Type of attack as factor\n",
    "df[\"type\"] = df[\"type\"].str.lower().str.strip().str.replace(\" +\", \" \", regex=True)\n",
    "df[\"type\"] = pd.Categorical(\n",
    "    df[\"type\"],\n",
    "    categories=[\"unprovoked\", \"provoked\", \"questionable\", \"watercraft\"],\n",
    "    ordered=False\n",
    ")\n",
    "\n",
    "# Age as integer\n",
    "df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Sex as factor\n",
    "df[\"sex\"] = df[\"sex\"].str.lower().str.strip().str.replace(\" +\", \" \", regex=True)\n",
    "df[\"sex\"] = pd.Categorical(\n",
    "    df[\"sex\"],\n",
    "    categories=[\"m\", \"f\"],\n",
    "    ordered=False\n",
    ")\n",
    "\n",
    "# Binary fatality status\n",
    "fatality_map = {\"Y\": 1, \"N\": 0}\n",
    "\n",
    "df[\"fatal\"] = df.pop(\"fatal_y_n\")\n",
    "df[\"fatal\"] = df[\"fatal\"].map(fatality_map)\n",
    "df[\"fatal\"] = pd.to_numeric(df[\"fatal\"], errors=\"coerce\").astype(\"Int16\")\n",
    "df[\"fatal\"] = pd.Categorical(\n",
    "    df[\"fatal\"],\n",
    "    categories=[0,1],\n",
    "    ordered=False\n",
    ")\n",
    "\n",
    "# Convert to lower case and purge whitespaces\n",
    "df[[\"date\", \"time\", \"activity\", \"injury\", \"species\"]] = (\n",
    "    df[[\"date\", \"time\", \"activity\", \"injury\", \"species\"]]\n",
    "    .apply(lambda col: col.str.lower().str.strip().str.replace(\" +\", \" \", regex=True))\n",
    ")\n",
    "\n",
    "# Purge whitespaces\n",
    "df[[\"country\", \"state\", \"location\", \"name\"]] = (\n",
    "    df[[\"country\", \"state\", \"location\", \"name\"]]\n",
    "    .apply(lambda col: col.str.title().str.strip().str.replace(\" +\", \" \", regex=True))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0227a1",
   "metadata": {},
   "source": [
    "### Clean the time column\n",
    "\n",
    "- recode `time` as time\n",
    "- construct a `time_of_day` column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "5840aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the raw column\n",
    "raw_time = df.time\n",
    "\n",
    "# Clean up the values\n",
    "hrs_mins = raw_time.str.extract(\"(\\\\d{1,2})[a-z]*?(\\\\d{2})\", expand=False)\n",
    "clean_time = hrs_mins[0].str.zfill(2) + \":\" + hrs_mins[1].str.zfill(2) # Pad the numbers\n",
    "\n",
    "# Override the original column with clean time values\n",
    "df[\"time\"] = pd.to_datetime(clean_time, format=\"%H:%M\", errors=\"coerce\").dt.time\n",
    "\n",
    "# Classify phases of day\n",
    "day_phases = r\"\"\"daybreak: 04:00–06:59\n",
    "morning: 07:00–11:59\n",
    "afternoon: 12:00–16:59\n",
    "nightfall: 17:00–20:59\n",
    "night: 21:00–03:59)\"\"\"\n",
    "\n",
    "# Match the string components\n",
    "day_phases_components = re.findall(\"([a-z]+): (\\\\d{2}:\\\\d{2})[-–](\\\\d{2}:\\\\d{2})\", day_phases)\n",
    "\n",
    "# Construct a key\n",
    "day_phases_key = pd.DataFrame(\n",
    "    day_phases_components,\n",
    "    columns=[\"phase\", \"start\", \"end\"]\n",
    ")\n",
    "\n",
    "day_phases_key[\"start\"] = pd.to_datetime(day_phases_key[\"start\"], format=\"%H:%M\").dt.time\n",
    "day_phases_key[\"end\"] = pd.to_datetime(day_phases_key[\"end\"], format=\"%H:%M\").dt.time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "1102d20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode day phases\n",
    "day_phases = []\n",
    "\n",
    "for i in range(len(raw_time)):\n",
    "    raw_t = raw_time[i]\n",
    "    raw_m = re.search(\"[a-z ]+\", str(raw_t))\n",
    "    if raw_m:\n",
    "        raw_s = raw_m.group()\n",
    "    else:\n",
    "        raw_s = None\n",
    "    clean_t = df.loc[i, \"time\"]\n",
    "\n",
    "    mask_s = day_phases_key.start > clean_t\n",
    "    mask_e = day_phases_key.end < clean_t\n",
    "    phase_row = day_phases_key[mask_s & mask_e]\n",
    "\n",
    "    # Categorise time vals\n",
    "    if pd.notna(clean_t):\n",
    "        if len(phase_row) > 0:\n",
    "            day_phases.append(phase_row[\"phase\"].iat[0])\n",
    "        else:\n",
    "            day_phases.append(\"night\")\n",
    "    # Sift out existing categories\n",
    "    elif raw_s is not None:\n",
    "        raw_split = raw_s.split(\" \")\n",
    "        a_match = set(day_phases_key[\"phase\"]).intersection(set(raw_split))\n",
    "        if len(a_match) > 0:\n",
    "            day_phases.append(raw_s)\n",
    "        else:\n",
    "            day_phases.append(None)\n",
    "    # Discard the rest\n",
    "    else:\n",
    "        day_phases.append(None)\n",
    "\n",
    "# Relocate time and time_of_day\n",
    "time_col_idx = df.columns.get_loc(\"year\") + 1\n",
    "time_col = df.pop(\"time\")\n",
    "df.insert(time_col_idx, \"time\", time_col)\n",
    "\n",
    "df.insert(time_col_idx + 1, \"time_of_day\", day_phases)\n",
    "\n",
    "# Recode time_of_day as factor\n",
    "df[\"time_of_day\"] = pd.Categorical(\n",
    "    df[\"time_of_day\"], \n",
    "    categories=df[\"time_of_day\"].dropna().unique(),\n",
    "    ordered=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2256a63",
   "metadata": {},
   "source": [
    "\n",
    "### Clean the date column\n",
    "\n",
    "- recode `date` as date\n",
    "- construct `date_notes` column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "890545bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct date_notes\n",
    "# df[\"date_notes\"] = df.pop(\"date\")\n",
    "df[\"date_notes\"] = df[\"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "7a99881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the column\n",
    "    # Take the reported for actual and remove suffixes\n",
    "date_raw = (\n",
    "    df[\"date_notes\"].astype(\"str\")\n",
    "    .str.replace(\"reported \", \"\", regex=True)\n",
    "    .str.replace(\"(?<=\\\\d)(st|nd|rd|th)\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "    # Parse the parsable and construct a mask for the rest\n",
    "date_parsed = pd.to_datetime(date_raw, errors=\"coerce\", format=\"mixed\")\n",
    "\n",
    "    # The case of D:M \n",
    "date_unparsed = date_parsed.isna()\n",
    "day_month = date_raw[date_unparsed].str.extract(\"(\\\\d{1,2}).*?([a-z]+)\")\n",
    "date_construct = df.loc[date_unparsed, \"year\"].astype(str) + \"-\" + day_month[1].str[:3] + \"-\" + day_month[0].str.zfill(2)\n",
    "\n",
    "date_parsed.loc[date_unparsed] = pd.to_datetime(date_construct, errors=\"coerce\", format=\"%Y-%b-%d\")\n",
    "\n",
    "    # The case of M:Y\n",
    "left_unparsed = date_parsed.isna()\n",
    "month_year = date_raw[left_unparsed].str.extract(\"([a-z]+).*?(\\\\d{4})\")\n",
    "month_construct = month_year[1] + \"-\" + month_year[0].str[:3] + \"-\" + \"01\"\n",
    "\n",
    "date_parsed.loc[left_unparsed] = pd.to_datetime(month_construct, errors=\"coerce\", format=\"%Y-%b-%d\")\n",
    "\n",
    "df[\"date\"] = date_parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b92d1d",
   "metadata": {},
   "source": [
    "### Clean species\n",
    "\n",
    "- normalise `species` column\n",
    "- construct `specimen_size` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "769efc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct size columns\n",
    "df[\"size_m\"] = df[\"species\"].str.extract(\"(\\\\d*\\\\.?\\\\d+)(?=m)\")\n",
    "df[\"size_ft\"] = df[\"species\"].str.extract(\"(\\\\d*\\\\.?\\\\d+)(?=ft)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "2f419f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the species column\n",
    "    # Correct typos\n",
    "typos_dict = {\n",
    "    \"wfite\": \"white\",\n",
    "    \"shart\": \"shark\",\n",
    "    \"broze\": \"bronze\",\n",
    "    \"carribean\": \"caribbean\",\n",
    "    \"galapogas\": \"galapagos\",\n",
    "    \"shall\": \"small\",\n",
    "    \"rreef\": \"reef\",\n",
    "    \"black-tipped\": \"blacktip\"\n",
    "}\n",
    "\n",
    "df[\"species\"] = df[\"species\"].replace(typos_dict, regex=True)\n",
    "\n",
    "    # Clean the species\n",
    "detect_substrings = [\n",
    "    df[\"species\"].str.contains(r\"bull.*tiger|tiger.*bull\", na=False),\n",
    "\n",
    "    df[\"species\"].str.contains(r\"oceanic whitetip\", na=False),\n",
    "    df[\"species\"].str.contains(r\"blacktip reef\", na=False),\n",
    "    df[\"species\"].str.contains(r\"caribbean reef\", na=False),\n",
    "    df[\"species\"].str.contains(r\"sand tiger|raggedtooth\", na=False),\n",
    "    df[\"species\"].str.contains(r\"sandbar\", na=False),\n",
    "    df[\"species\"].str.contains(r\"bronze whaler\", na=False),\n",
    "    df[\"species\"].str.contains(r\"wobbegong\", na=False),\n",
    "    df[\"species\"].str.contains(r\"sevengill\", na=False),\n",
    "    df[\"species\"].str.contains(r\"cookiecutter\", na=False),\n",
    "    df[\"species\"].str.contains(r\"grey reef\", na=False),\n",
    "    df[\"species\"].str.contains(r\"reef shark\", na=False),\n",
    "\n",
    "    df[\"species\"].str.contains(r\"shovelnose guitarfish\", na=False),\n",
    "    df[\"species\"].str.contains(r\"whale shark\", na=False),\n",
    "    df[\"species\"].str.contains(r\"horn shark|horn\", na=False),\n",
    "    df[\"species\"].str.contains(r\"hammerhead\", na=False),\n",
    "\n",
    "    df[\"species\"].str.contains(r\"lemon\", na=False),\n",
    "    df[\"species\"].str.contains(r\"nurse\", na=False),\n",
    "    df[\"species\"].str.contains(r\"blacktip\", na=False),\n",
    "    df[\"species\"].str.contains(r\"mako\", na=False),\n",
    "    df[\"species\"].str.contains(r\"blue pointer\", na=False),\n",
    "    df[\"species\"].str.contains(r\"blue\", na=False),\n",
    "    df[\"species\"].str.contains(r\"dusky\", na=False),\n",
    "    df[\"species\"].str.contains(r\"galapagos\", na=False),\n",
    "    df[\"species\"].str.contains(r\"reef\", na=False),\n",
    "\n",
    "    df[\"species\"].str.contains(r\"porbeagle\", na=False),\n",
    "    df[\"species\"].str.contains(r\"basking\", na=False),\n",
    "\n",
    "    df[\"species\"].str.contains(r\"bull\", na=False),\n",
    "    df[\"species\"].str.contains(r\"tiger\", na=False),\n",
    "    df[\"species\"].str.contains(r\"great white|white shark\", na=False),\n",
    "]\n",
    "\n",
    "substitute_strings = [\n",
    "    \"bull or tiger shark\",\n",
    "\n",
    "    \"oceanic whitetip shark\",\n",
    "    \"blacktip reef shark\",\n",
    "    \"caribbean reef shark\",\n",
    "    \"sand tiger shark\",\n",
    "    \"sandbar shark\",\n",
    "    \"bronze whaler\",\n",
    "    \"wobbegong shark\",\n",
    "    \"sevengill shark\",\n",
    "    \"cookiecutter shark\",\n",
    "    \"grey reef shark\",\n",
    "    \"reef shark\",\n",
    "\n",
    "    \"shovelnose guitarfish\",\n",
    "    \"whale shark\",\n",
    "    \"horn shark\",\n",
    "    \"hammerhead shark\",\n",
    "\n",
    "    \"lemon shark\",\n",
    "    \"nurse shark\",\n",
    "    \"blacktip shark\",\n",
    "    \"mako shark\",\n",
    "    \"blue pointer\",\n",
    "    \"blue shark\",\n",
    "    \"dusky shark\",\n",
    "    \"galapagos shark\",\n",
    "    \"reef shark\",\n",
    "\n",
    "    \"porbeagle shark\",\n",
    "    \"basking shark\",\n",
    "\n",
    "    \"bull shark\",\n",
    "    \"tiger shark\",\n",
    "    \"white shark\",\n",
    "]\n",
    "\n",
    "df[\"species\"] = np.select(detect_substrings, substitute_strings, default=\"\")\n",
    "df[\"species\"] = df[\"species\"].replace(\"\", np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb1286c",
   "metadata": {},
   "source": [
    "### Final touches\n",
    "\n",
    "- select cols\n",
    "- filter out NA years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "8eff090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_cols = [\n",
    "    \"date\", \"year\", \"time\", \"time_of_day\", \n",
    "    \"type\", \n",
    "    \"country\", \"state\", \"location\", \n",
    "    \"activity\", \"name\", \"sex\", \n",
    "    \"injury\", \"fatal\", \n",
    "    \"species\", \"size_m\", \"size_ft\"\n",
    "    ]\n",
    "clean_df = df[clean_cols]\n",
    "clean_df = clean_df[clean_df[\"year\"].notna()]\n",
    "clean_df = clean_df[clean_df[\"year\"] > 1900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "d5d83d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>time</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>type</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>location</th>\n",
       "      <th>activity</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>injury</th>\n",
       "      <th>fatal</th>\n",
       "      <th>species</th>\n",
       "      <th>size_m</th>\n",
       "      <th>size_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>2025</td>\n",
       "      <td>06:30:00</td>\n",
       "      <td>night</td>\n",
       "      <td>unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Nsw</td>\n",
       "      <td>Crowdy Bay</td>\n",
       "      <td>swimming</td>\n",
       "      <td>Lukas Schindler</td>\n",
       "      <td>m</td>\n",
       "      <td>serious leg injuries</td>\n",
       "      <td>0</td>\n",
       "      <td>bull shark</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>2025</td>\n",
       "      <td>06:30:00</td>\n",
       "      <td>night</td>\n",
       "      <td>unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Nsw</td>\n",
       "      <td>Crowdy Bay</td>\n",
       "      <td>swimming</td>\n",
       "      <td>Livia Mulheim</td>\n",
       "      <td>f</td>\n",
       "      <td>not stated</td>\n",
       "      <td>1</td>\n",
       "      <td>bull shark</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-10</td>\n",
       "      <td>2025</td>\n",
       "      <td>17:45:00</td>\n",
       "      <td>night</td>\n",
       "      <td>unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>Prevelly Beach Magaret River</td>\n",
       "      <td>foil boarding</td>\n",
       "      <td>Andy Mcdonald</td>\n",
       "      <td>m</td>\n",
       "      <td>no injury to self</td>\n",
       "      <td>0</td>\n",
       "      <td>white shark</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-09</td>\n",
       "      <td>2025</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unprovoked</td>\n",
       "      <td>French Polynesia</td>\n",
       "      <td>Marquesas Islands</td>\n",
       "      <td>Hakahau Bay</td>\n",
       "      <td>swimming</td>\n",
       "      <td>Not Stated (Dentist)</td>\n",
       "      <td>m</td>\n",
       "      <td>deep gash to bicep</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>2025</td>\n",
       "      <td>NaT</td>\n",
       "      <td>mid afternoon</td>\n",
       "      <td>unprovoked</td>\n",
       "      <td>Usa</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Pine Trees Hanalei Bay Kaui</td>\n",
       "      <td>swimming</td>\n",
       "      <td>Chance Swanson</td>\n",
       "      <td>m</td>\n",
       "      <td>injuries to legs</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>2025</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unprovoked</td>\n",
       "      <td>Usa</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Matagorda Beach Matagorda</td>\n",
       "      <td>fishing</td>\n",
       "      <td>Chuck Bledsoe</td>\n",
       "      <td>m</td>\n",
       "      <td>laceration on top and undermeath right foot</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>2025</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>night</td>\n",
       "      <td>unprovoked</td>\n",
       "      <td>Samoa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aga Reef Resort Lalomanu</td>\n",
       "      <td>surfing</td>\n",
       "      <td>Evan Campbell</td>\n",
       "      <td>m</td>\n",
       "      <td>lacerations to right leg</td>\n",
       "      <td>0</td>\n",
       "      <td>tiger shark</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-10-14</td>\n",
       "      <td>2025</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unprovoked</td>\n",
       "      <td>Columbia</td>\n",
       "      <td>Bolivar, Del Isolate</td>\n",
       "      <td>Catagena Province</td>\n",
       "      <td>swimming with sharks</td>\n",
       "      <td>Male Child</td>\n",
       "      <td>m</td>\n",
       "      <td>severe hand injury</td>\n",
       "      <td>0</td>\n",
       "      <td>nurse shark</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-10-11</td>\n",
       "      <td>2025</td>\n",
       "      <td>18:23:00</td>\n",
       "      <td>night</td>\n",
       "      <td>unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>Cook Esplanade Thursday Island</td>\n",
       "      <td>fishing/swimming</td>\n",
       "      <td>Samuel Nai</td>\n",
       "      <td>m</td>\n",
       "      <td>serious abdonminal injuries</td>\n",
       "      <td>0</td>\n",
       "      <td>bull or tiger shark</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-10-07</td>\n",
       "      <td>2025</td>\n",
       "      <td>13:30:00</td>\n",
       "      <td>night</td>\n",
       "      <td>unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>Kangaroo Island</td>\n",
       "      <td>surfing</td>\n",
       "      <td>Lee Berryman</td>\n",
       "      <td>m</td>\n",
       "      <td>lacerations to calf</td>\n",
       "      <td>0</td>\n",
       "      <td>bronze whaler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  year      time    time_of_day        type           country  \\\n",
       "0 2025-11-27  2025  06:30:00          night  unprovoked         Australia   \n",
       "1 2025-11-27  2025  06:30:00          night  unprovoked         Australia   \n",
       "2 2025-11-10  2025  17:45:00          night  unprovoked         Australia   \n",
       "3 2025-11-09  2025       NaT            NaN  unprovoked  French Polynesia   \n",
       "4 2025-11-05  2025       NaT  mid afternoon  unprovoked               Usa   \n",
       "5 2025-11-05  2025       NaT            NaN  unprovoked               Usa   \n",
       "6 2025-11-04  2025  18:00:00          night  unprovoked             Samoa   \n",
       "7 2025-10-14  2025       NaT            NaN  unprovoked          Columbia   \n",
       "8 2025-10-11  2025  18:23:00          night  unprovoked         Australia   \n",
       "9 2025-10-07  2025  13:30:00          night  unprovoked         Australia   \n",
       "\n",
       "                  state                        location              activity  \\\n",
       "0                   Nsw                      Crowdy Bay              swimming   \n",
       "1                   Nsw                      Crowdy Bay              swimming   \n",
       "2     Western Australia    Prevelly Beach Magaret River         foil boarding   \n",
       "3     Marquesas Islands                     Hakahau Bay              swimming   \n",
       "4                Hawaii     Pine Trees Hanalei Bay Kaui              swimming   \n",
       "5                 Texas       Matagorda Beach Matagorda               fishing   \n",
       "6                   NaN        Aga Reef Resort Lalomanu               surfing   \n",
       "7  Bolivar, Del Isolate               Catagena Province  swimming with sharks   \n",
       "8            Queensland  Cook Esplanade Thursday Island      fishing/swimming   \n",
       "9       South Australia                 Kangaroo Island               surfing   \n",
       "\n",
       "                   name sex                                       injury  \\\n",
       "0       Lukas Schindler   m                         serious leg injuries   \n",
       "1         Livia Mulheim   f                                   not stated   \n",
       "2         Andy Mcdonald   m                            no injury to self   \n",
       "3  Not Stated (Dentist)   m                           deep gash to bicep   \n",
       "4        Chance Swanson   m                             injuries to legs   \n",
       "5         Chuck Bledsoe   m  laceration on top and undermeath right foot   \n",
       "6         Evan Campbell   m                     lacerations to right leg   \n",
       "7            Male Child   m                           severe hand injury   \n",
       "8            Samuel Nai   m                  serious abdonminal injuries   \n",
       "9          Lee Berryman   m                          lacerations to calf   \n",
       "\n",
       "  fatal              species size_m size_ft  \n",
       "0     0           bull shark      3     NaN  \n",
       "1     1           bull shark      3     NaN  \n",
       "2     0          white shark    NaN     NaN  \n",
       "3     0                  NaN      3     NaN  \n",
       "4     0                  NaN    NaN     NaN  \n",
       "5     0                  NaN    NaN     NaN  \n",
       "6     0          tiger shark    NaN     NaN  \n",
       "7     0          nurse shark    NaN     NaN  \n",
       "8     0  bull or tiger shark    NaN     NaN  \n",
       "9     0        bronze whaler    NaN     NaN  "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a80989",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5f8384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
